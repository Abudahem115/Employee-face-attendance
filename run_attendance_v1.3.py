import cv2
import face_recognition
import numpy as np
from modules import db_manager
import time
import os
from datetime import datetime
from scipy.spatial import distance as dist

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹ ---
CONFIDENCE_THRESHOLD = 0.50
EYE_ASPECT_RATIO_THRESHOLD = 0.25
CONSECUTIVE_FRAMES = 2        # Ù‚Ù„Ù„Ù†Ø§ Ø§Ù„Ø¹Ø¯Ø¯ Ø¥Ù„Ù‰ 2 Ù„Ø£Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø³ØªÙƒÙˆÙ† Ø£Ø³Ø±Ø¹
COOLDOWN_SECONDS = 60

# ØªØ¬Ù‡ÙŠØ² Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¯Ù„Ø©
EVIDENCE_DIR = "attendance_evidence"
if not os.path.exists(EVIDENCE_DIR):
    os.makedirs(EVIDENCE_DIR)

def get_eye_aspect_ratio(eye):
    """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© ÙØªØ­Ø© Ø§Ù„Ø¹ÙŠÙ†"""
    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    C = dist.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

def save_evidence(frame, name):
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"{EVIDENCE_DIR}/{name}_{timestamp}.jpg"
    cv2.imwrite(filename, frame)
    print(f"ğŸ“¸ Evidence saved: {filename}")

def main():
    print("--- âš¡ Fast Pro System: Liveness & Security (V4) ---")
    
    users = db_manager.get_all_embeddings()
    known_face_encodings = [user["encoding"] for user in users]
    known_face_names = [user["name"] for user in users]
    known_face_ids = [user["id"] for user in users]
    
    last_attendance = {}
    blink_counter = 0
    is_eye_closed = False

    # 0 Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©ØŒ ÙˆØ¬Ø±Ø¨ 1 Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ ÙƒØ§Ù…ÙŠØ±Ø§ Ø®Ø§Ø±Ø¬ÙŠØ©
    video_capture = cv2.VideoCapture(0)
    
    # ØªØ­Ø³ÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§)
    video_capture.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    print("ğŸŸ¢ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¬Ø§Ù‡Ø²... (Ø§Ø±Ù…Ø´ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ±!) ğŸ˜‰")

    while True:
        ret, frame = video_capture.read()
        if not ret: break

        # ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ±Ø© (Ù‡Ù†Ø§ Ø§Ù„Ø³Ø± ÙÙŠ Ø§Ù„Ø³Ø±Ø¹Ø©)
        # Ù†Ø³ØªØ®Ø¯Ù… 0.25 (Ø§Ù„Ø±Ø¨Ø¹) Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        # 1. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡
        face_locations = face_recognition.face_locations(rgb_small_frame)
        
        if len(face_locations) > 0:
            # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ØµÙ…Ø© + Ø§Ù„Ù…Ø¹Ø§Ù„Ù… (Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØµØºÙŠØ±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø±Ø¹Ø©) ğŸ”¥
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
            
            # Ù…Ù„Ø§Ø­Ø¸Ø©: face_landmarks ØªØ­ØªØ§Ø¬ Ù„Ù„ØµÙˆØ±Ø©ØŒ Ù„ÙƒÙ†Ù†Ø§ Ø³Ù†Ù…Ø±Ø± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØµØºÙŠØ±Ø© Ø§Ù„Ø¢Ù†
            face_landmarks_list = face_recognition.face_landmarks(rgb_small_frame, face_locations)

            # Ù†ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ ÙˆØ¬Ù‡ ÙˆØ§Ø­Ø¯ Ù„Ù„ØªØ¨Ø³ÙŠØ· ÙˆØ§Ù„Ø³Ø±Ø¹Ø©
            face_encoding = face_encodings[0]
            face_loc = face_locations[0]
            
            # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© ---
            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)
            
            name = "Unknown"
            color = (0, 0, 255)
            status_text = "Look at Camera"

            if face_distances[best_match_index] < CONFIDENCE_THRESHOLD:
                name = known_face_names[best_match_index]
                user_id = known_face_ids[best_match_index]
                
                # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…Ø´ (Liveness) ---
                if len(face_landmarks_list) > 0:
                    face_landmarks = face_landmarks_list[0]
                    left_eye = face_landmarks['left_eye']
                    right_eye = face_landmarks['right_eye']

                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© (Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø§ ØªØªØ£Ø«Ø± Ø¨ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„Ø£Ù†Ù‡Ø§ Ù‚Ø³Ù…Ø©)
                    leftEAR = get_eye_aspect_ratio(left_eye)
                    rightEAR = get_eye_aspect_ratio(right_eye)
                    avgEAR = (leftEAR + rightEAR) / 2.0

                    # ÙØ­Øµ Ø§Ù„Ø±Ù…Ø´
                    if avgEAR < EYE_ASPECT_RATIO_THRESHOLD:
                        blink_counter += 1
                        status_text = "Blinking..."
                    else:
                        if blink_counter >= CONSECUTIVE_FRAMES:
                            is_eye_closed = True
                        blink_counter = 0
                        status_text = "Verified - Blink Now"

                # --- Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ---
                if is_eye_closed:
                    color = (0, 255, 0)
                    status_text = f"Confirmed: {name}"
                    
                    current_time = time.time()
                    if user_id not in last_attendance or (current_time - last_attendance[user_id] > COOLDOWN_SECONDS):
                        db_manager.mark_attendance(user_id)
                        save_evidence(frame, name) # Ù†Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙƒØ¯Ù„ÙŠÙ„
                        last_attendance[user_id] = current_time
                        is_eye_closed = False
                        print(f"âœ… Fast Attendance: {name}")

            else:
                status_text = "Unknown Person"

            # Ø§Ù„Ø±Ø³Ù… (Ù†Ø¶Ø±Ø¨ ÙÙŠ 4 Ù„Ø£Ù†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØµØºÙŠØ±Ø©)
            top, right, bottom, left = face_loc
            top *= 4; right *= 4; bottom *= 4; left *= 4
            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
            cv2.putText(frame, status_text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.putText(frame, name, (left, bottom + 30), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)

        cv2.imshow('Fast Security Attendance', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    video_capture.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()