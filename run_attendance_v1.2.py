import cv2
import face_recognition
import numpy as np
from modules import db_manager
import time
import os
from datetime import datetime
from scipy.spatial import distance as dist # Ù†Ø­ØªØ§Ø¬ Ù„ØªØ«Ø¨ÙŠØª scipy Ø£Ùˆ Ù†Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ù„Ø© math

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ ---
CONFIDENCE_THRESHOLD = 0.50   # Ø¯Ù‚Ø© Ø§Ù„ØªØ¹Ø±Ù (ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø´Ø¯Ø© ÙˆØ§Ù„Ù…Ø±ÙˆÙ†Ø©)
EYE_ASPECT_RATIO_THRESHOLD = 0.25 # Ø¥Ø°Ø§ Ù†Ø²Ù„ Ø§Ù„Ø±Ù‚Ù… ØªØ­Øª Ù‡Ø°Ø§ Ø§Ù„Ø­Ø¯ØŒ ØªØ¹ØªØ¨Ø± Ø§Ù„Ø¹ÙŠÙ† Ù…ØºÙ„Ù‚Ø©
CONSECUTIVE_FRAMES = 3        # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±Ù…Ø´Ø© (Ù„Ù…Ù†Ø¹ Ø§Ù„Ø®Ø·Ø£)
COOLDOWN_SECONDS = 60         # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±

# ØªØ¬Ù‡ÙŠØ² Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¯Ù„Ø©
EVIDENCE_DIR = "attendance_evidence"
if not os.path.exists(EVIDENCE_DIR):
    os.makedirs(EVIDENCE_DIR)

def get_eye_aspect_ratio(eye):
    """
    Ø¯Ø§Ù„Ø© Ø±ÙŠØ§Ø¶ÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© ÙØªØ­Ø© Ø§Ù„Ø¹ÙŠÙ†.
    ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠØ© ÙˆØ§Ù„Ø§ÙÙ‚ÙŠØ© Ø¨ÙŠÙ† Ù†Ù‚Ø§Ø· Ø§Ù„Ø¹ÙŠÙ†.
    """
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠØ© (Ø¨ÙŠÙ† Ø§Ù„Ø¬ÙÙ† Ø§Ù„Ø¹Ù„ÙˆÙŠ ÙˆØ§Ù„Ø³ÙÙ„ÙŠ)
    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£ÙÙ‚ÙŠØ© (Ø¹Ø±Ø¶ Ø§Ù„Ø¹ÙŠÙ†)
    C = dist.euclidean(eye[0], eye[3])
    # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©
    ear = (A + B) / (2.0 * C)
    return ear

def save_evidence(frame, name):
    """Ø­ÙØ¸ ØµÙˆØ±Ø© Ø§Ù„Ø´Ø®Øµ Ù„Ø­Ø¸Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ± ÙƒØ¯Ù„ÙŠÙ„"""
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"{EVIDENCE_DIR}/{name}_{timestamp}.jpg"
    cv2.imwrite(filename, frame)
    print(f"ğŸ“¸ Evidence saved: {filename}")

def main():
    print("--- ğŸ›¡ï¸ Pro System: Liveness & Security (V3) ---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    users = db_manager.get_all_users()
    known_face_encodings = [user["encoding"] for user in users]
    known_face_names = [user["name"] for user in users]
    known_face_ids = [user["id"] for user in users]
    
    # Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø©
    last_attendance = {}
    blink_counter = 0      # Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ù…Ø´Ø§Øª
    total_blinks = 0       # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ù…Ø´Ø§Øª Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
    is_eye_closed = False  # Ø­Ø§Ù„Ø© Ø§Ù„Ø¹ÙŠÙ†

    video_capture = cv2.VideoCapture(0)
    print("ğŸŸ¢ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø²... (ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ù…Ø´ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ±!) ğŸ˜‰")

    while True:
        ret, frame = video_capture.read()
        if not ret: break

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        # 1. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
        
        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙˆØ¬Ù‡ (Ø§Ù„Ø¹ÙŠÙ†ÙŠÙ†) Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±Ù…Ø´
        # Ù†Ø­ØªØ§Ø¬ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù„Ù„Ø¯Ù‚Ø© ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¹ÙŠÙ†
        face_landmarks_list = face_recognition.face_landmarks(frame) 

        name = "Unknown"
        color = (0, 0, 255) # Ø£Ø­Ù…Ø±
        status_text = "Look at Camera"

        # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ ÙˆØ¬Ù‡Ø§Ù‹
        if len(face_encodings) > 0:
            # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ ÙˆØ¬Ù‡ ÙÙ‚Ø· Ù„Ù„ØªØ¨Ø³ÙŠØ·
            face_encoding = face_encodings[0]
            
            # --- Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¹Ø±Ù (Identity Check) ---
            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)
            
            if face_distances[best_match_index] < CONFIDENCE_THRESHOLD:
                name = known_face_names[best_match_index]
                user_id = known_face_ids[best_match_index]
                
                # --- Ù…Ø±Ø­Ù„Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙŠÙˆÙŠØ© (Liveness Check) ---
                # Ù†ØªØ­Ù‚Ù‚ Ù‡Ù„ ÙˆØ¬Ø¯Ù†Ø§ Ù…Ø¹Ø§Ù„Ù… Ù„Ù„ÙˆØ¬Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø·Ø§Ø±ØŸ
                if len(face_landmarks_list) > 0:
                    face_landmarks = face_landmarks_list[0]
                    left_eye = face_landmarks['left_eye']
                    right_eye = face_landmarks['right_eye']

                    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© ÙØªØ­Ø© Ø§Ù„Ø¹ÙŠÙ†
                    leftEAR = get_eye_aspect_ratio(left_eye)
                    rightEAR = get_eye_aspect_ratio(right_eye)
                    avgEAR = (leftEAR + rightEAR) / 2.0

                    # ÙØ­Øµ Ø§Ù„Ø±Ù…Ø´
                    if avgEAR < EYE_ASPECT_RATIO_THRESHOLD:
                        blink_counter += 1
                        status_text = "Blinking..."
                    else:
                        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹ÙŠÙ† Ù…ØºÙ„Ù‚Ø© Ù„ÙØªØ±Ø© ÙƒØ§ÙÙŠØ© Ø«Ù… ÙØªØ­Øª -> Ù‡Ø°Ù‡ Ø±Ù…Ø´Ø© ÙƒØ§Ù…Ù„Ø©
                        if blink_counter >= CONSECUTIVE_FRAMES:
                            total_blinks += 1
                            is_eye_closed = True # ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø±Ù…Ø´Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©
                        blink_counter = 0
                        status_text = "Face Verified - Please Blink"

                # --- Ù‚Ø±Ø§Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ---
                # Ø§Ù„Ø´Ø±Ø·: Ø§Ù„ÙˆØ¬Ù‡ Ù…Ø¹Ø±ÙˆÙ + ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø±Ù…Ø´Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
                if is_eye_closed:
                    color = (0, 255, 0) # Ø£Ø®Ø¶Ø±
                    status_text = f"Confirmed: {name}"
                    
                    current_time = time.time()
                    if user_id not in last_attendance or (current_time - last_attendance[user_id] > COOLDOWN_SECONDS):
                        # 1. ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
                        db_manager.mark_attendance(user_id)
                        # 2. Ø­ÙØ¸ ØµÙˆØ±Ø© Ø§Ù„Ø¯Ù„ÙŠÙ„
                        save_evidence(frame, name)
                        last_attendance[user_id] = current_time
                        
                        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø±Ù…Ø´ Ù„Ù„Ù…Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
                        is_eye_closed = False 
                        total_blinks = 0
                        print(f"âœ… Real Human Detected: {name}")

            else:
                status_text = "Unknown Person"

            # Ø§Ù„Ø±Ø³Ù…
            top, right, bottom, left = face_locations[0]
            top *= 4; right *= 4; bottom *= 4; left *= 4
            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
            cv2.putText(frame, status_text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.putText(frame, name, (left, bottom + 30), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)

        cv2.imshow('Security Attendance V3', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    video_capture.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()