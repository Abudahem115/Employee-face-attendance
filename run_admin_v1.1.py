import cv2
import face_recognition
import os
import numpy as np
from modules import db_manager
import time

def main():
    print("\n--- ğŸ‘¤ Smart Employee Registration (Live Capture) ---")
    
    # ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    db_manager.init_db()
    
    name = input("Enter Employee Name: ").strip()
    if not name:
        print("âŒ Name cannot be empty.")
        return

    print(f"\nğŸ¥ Opening camera for {name}...")
    print("Please rotate your head slightly (Left, Right, Center) to capture angles.")
    
    video_capture = cv2.VideoCapture(0)
    
    captured_encodings = []
    REQUIRED_SAMPLES = 15  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø§Ù„ØªÙ‚Ø§Ø·Ù‡Ø§ (ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯ØŒ Ø²Ø§Ø¯Øª Ø§Ù„Ø¯Ù‚Ø©)
    
    while len(captured_encodings) < REQUIRED_SAMPLES:
        ret, frame = video_capture.read()
        if not ret: break
        
        # Ù†Ø³Ø®Ø© Ù„Ù„Ø¹Ø±Ø¶
        display_frame = frame.copy()
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ÙƒØ´Ù Ø§Ù„ÙˆØ¬Ù‡
        face_locations = face_recognition.face_locations(rgb_frame)
        
        if len(face_locations) == 1:
            # ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙˆØ§Ø­Ø¯ Ø¨Ø§Ù„Ø¶Ø¨Ø· (Ù…Ù…ØªØ§Ø²)
            top, right, bottom, left = face_locations[0]
            
            # Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹ Ø£Ø®Ø¶Ø±
            cv2.rectangle(display_frame, (left, top), (right, bottom), (0, 255, 0), 2)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ØµÙ…Ø©
            try:
                face_encoding = face_recognition.face_encodings(rgb_frame, face_locations)[0]
                captured_encodings.append(face_encoding)
                
                # ÙˆÙ…ÙŠØ¶ Ø£Ø¨ÙŠØ¶ Ø¨Ø³ÙŠØ· (Visual Feedback)
                cv2.rectangle(display_frame, (0, 0), (frame.shape[1], frame.shape[0]), (255, 255, 255), 10)
                
                print(f"ğŸ“¸ Captured {len(captured_encodings)}/{REQUIRED_SAMPLES}")
                time.sleep(0.1) # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±
            except:
                pass
                
        elif len(face_locations) > 1:
            cv2.putText(display_frame, "One person only!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        else:
            cv2.putText(display_frame, "Looking for face...", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

        # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
        progress = f"Progress: {len(captured_encodings)}/{REQUIRED_SAMPLES}"
        cv2.putText(display_frame, progress, (50, frame.shape[0] - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        cv2.imshow('Registration Mode', display_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("âŒ Cancelled by user.")
            return

    video_capture.release()
    cv2.destroyAllWindows()
    
    # Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if len(captured_encodings) == REQUIRED_SAMPLES:
        print("\nğŸ’¾ Saving data to database...")
        db_manager.add_user_with_encodings(name, captured_encodings)
        print("ğŸ‰ Registration Complete! System is now trained on your face.")
    else:
        print("âŒ Registration failed/incomplete.")

if __name__ == "__main__":
    main()